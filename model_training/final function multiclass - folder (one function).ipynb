{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6adfd8d1-0f25-4e66-a6ca-b20b27533854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-12 12:16:54.491529: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from glob import glob\n",
    "import PIL\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.xception import preprocess_input as preprocess_xception\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as preprocess_densenet\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input as preprocess_vgg\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as preprocess_inception\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_resnet\n",
    "from tensorflow.keras.utils import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7646ec1d-ff54-4981-8d07-52d06d52faf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-12 12:16:56.010484: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 12:16:56.015414: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 12:16:56.017591: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 12:16:56.020852: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 12:16:56.022961: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 12:16:56.025048: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 12:16:56.136017: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 12:16:56.137475: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 12:16:56.138713: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-12 12:16:56.139992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22084 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-05-12 12:17:00.918656: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:432] Loaded cuDNN version 8800\n",
      "2024-05-12 12:17:00.979117: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-05-12 12:17:00.979643: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-05-12 12:17:00.979661: W tensorflow/compiler/xla/stream_executor/gpu/asm_compiler.cc:109] Couldn't get ptxas version : FAILED_PRECONDITION: Couldn't get ptxas/nvlink version string: INTERNAL: Couldn't invoke ptxas --version\n",
      "2024-05-12 12:17:00.980223: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-05-12 12:17:00.980263: W tensorflow/compiler/xla/stream_executor/gpu/redzone_allocator.cc:318] INTERNAL: Failed to launch ptxas\n",
      "Relying on driver to perform ptx compilation. \n",
      "Modify $PATH to customize ptxas location.\n",
      "This message will be only logged once.\n",
      "2024-05-12 12:17:01.060439: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:606] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 507ms/step\n",
      "1/1 [==============================] - 1s 726ms/step\n",
      "1/1 [==============================] - 1s 828ms/step\n",
      "1/1 [==============================] - 0s 121ms/step\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x75c258709240> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 593ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 16ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Final prediction: cubiti dextra\n"
     ]
    }
   ],
   "source": [
    "def body_part_detect(folder_path, model_paths, meta_model_file, template_paths, df_test):\n",
    "    # Load models\n",
    "    densenet_model = load_model(model_paths[0])\n",
    "    xception_model = load_model(model_paths[1])\n",
    "    inception_model = load_model(model_paths[2])\n",
    "    vgg_model = load_model(model_paths[3])\n",
    "    resnet_model = load_model(model_paths[4])\n",
    "\n",
    "    with open(meta_model_file, 'rb') as file:\n",
    "        meta_model = pickle.load(file)\n",
    "    \n",
    "    template_images = [cv2.imread(path) for path in template_paths]\n",
    "\n",
    "    # Helper functions\n",
    "    def preprocess_image(img_path, model_name):\n",
    "\n",
    "        # Load a grayscale image\n",
    "        img = load_img(img_path, color_mode='grayscale', target_size=(224, 224))\n",
    "        \n",
    "        # Convert the image to a numpy array\n",
    "        img_array = img_to_array(img)\n",
    "        \n",
    "        # Replicate the grayscale channel three times to create a pseudo-RGB image\n",
    "        pseudo_rgb_img = np.repeat(img_array, 3, axis=2)\n",
    "    \n",
    "        if model_name == 'xception':\n",
    "            processed_img = preprocess_xception(pseudo_rgb_img)\n",
    "        elif model_name == 'densenet':\n",
    "            processed_img = preprocess_densenet(pseudo_rgb_img)\n",
    "        elif model_name == 'inception':\n",
    "            processed_img = preprocess_inception(pseudo_rgb_img)\n",
    "        elif model_name == 'vgg':\n",
    "            processed_img = preprocess_vgg(pseudo_rgb_img)\n",
    "        elif model_name == 'resnet':\n",
    "            processed_img = preprocess_resnet(pseudo_rgb_img)\n",
    "            \n",
    "        return processed_img\n",
    " \n",
    "    def generate_predictions(model, dataset):\n",
    "        predictions = model.predict(dataset)\n",
    "        return predictions.reshape(predictions.shape[0], -1)\n",
    "\n",
    "    def detect_position(image, template_images):\n",
    "        idx_pos = []\n",
    "        for idx, template in enumerate(template_images):\n",
    "            template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "            template_gray_flip = cv2.flip(template_gray, 1) \n",
    "    \n",
    "            # template matching template_gray\n",
    "            match_result = cv2.matchTemplate(image, template_gray, cv2.TM_CCOEFF_NORMED)      \n",
    "            # get max_val to know the detection confidence\n",
    "            _, max_val, _, _ = cv2.minMaxLoc(match_result)\n",
    "    \n",
    "            # template matching template_gray_flip\n",
    "            match_result_flip = cv2.matchTemplate(image, template_gray_flip, cv2.TM_CCOEFF_NORMED)      \n",
    "            # get max_val to know the detection confidence\n",
    "            _, max_val_flip, _, _ = cv2.minMaxLoc(match_result_flip)\n",
    "    \n",
    "            # if confident more than 85% return the idx\n",
    "            if max_val >= 0.85:\n",
    "                idx_pos.append(idx)\n",
    "            elif max_val_flip >= 0.85:\n",
    "                idx_pos.append(idx)\n",
    "        return idx_pos\n",
    "\n",
    "    patient_predictions = defaultdict(list)\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(img_path) and img_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            model_predictions = []\n",
    "            model_names = ['xception', 'densenet', 'inception', 'vgg', 'resnet']\n",
    "            models = [xception_model, densenet_model, inception_model, vgg_model, resnet_model]\n",
    "            \n",
    "            for idx, m in enumerate(model_names):\n",
    "                img = preprocess_image(img_path, m)\n",
    "                img = np.expand_dims(img, axis=0)  # Add a new dimension at the beginning\n",
    "                model_predictions.append(generate_predictions(models[idx], img))\n",
    "            \n",
    "            # Vertically stack the predictions from all models\n",
    "            aggregated_preds = np.hstack(model_predictions)\n",
    "            \n",
    "            predicted_multiclass_label = meta_model.predict(aggregated_preds)\n",
    "            confidence_score = np.max(meta_model.predict_proba(aggregated_preds))\n",
    "    \n",
    "            # Store predictions with confidence\n",
    "            patient_predictions[predicted_multiclass_label[0]].append(confidence_score)\n",
    "\n",
    "    predicted_multiclass_label = max(patient_predictions, key=lambda x: sum(patient_predictions[x]))\n",
    "    \n",
    "    df_test = pd.read_csv(df_test)\n",
    "\n",
    "    # Initialize the LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit_transform(df_test['body_part'])\n",
    "    predicted_body_part = label_encoder.inverse_transform([predicted_multiclass_label])[0]\n",
    "    \n",
    "    # Final prediction and formatting\n",
    "    combined_result = predicted_body_part\n",
    "    skip_body_part = ['abdomen', 'kepala', 'os_sacro_coccygeus', 'pelvis', 'thorax', 'vertebra_cervical', 'vertebra_lumbosakral', 'vertebra_thoracolumbal']\n",
    "\n",
    "\n",
    "    if predicted_body_part not in skip_body_part:\n",
    "        position_list = []\n",
    "\n",
    "        for filename in os.listdir(folder_path):\n",
    "                # Loop through each image\n",
    "                img_path = os.path.join(folder_path, filename)\n",
    "                if os.path.isfile(img_path) and img_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    image = cv2.imread(img_path)\n",
    "                    # plt.imshow(image)\n",
    "                    # plt.show()\n",
    "                    \n",
    "                    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY).astype(np.uint8)\n",
    "                    idx_pos = detect_position(image_gray, template_images)\n",
    "                \n",
    "                    # append position\n",
    "                    if any(i in idx_pos for i in range(5)) and any(i in idx_pos for i in range(5, 13)):\n",
    "                        position_list.append('right')\n",
    "                        position_list.append('left')\n",
    "                    elif any(i in idx_pos for i in range(5)):\n",
    "                        position_list.append('left')\n",
    "                    elif any(i in idx_pos for i in range(5, 13)):\n",
    "                        position_list.append('right')\n",
    "                \n",
    "        if len(position_list) > 0:            \n",
    "            if 'right' in position_list and 'left' in position_list:\n",
    "                position = 'bilateral'\n",
    "            elif 'right' in position_list:\n",
    "                position = 'dextra'\n",
    "            elif 'left' in position_list:\n",
    "                position = 'sinistra'\n",
    "            combined_result += ' ' + position\n",
    "    \n",
    "    else:\n",
    "        combined_result += 'None'\n",
    "\n",
    "    average_confidence = np.mean(patient_predictions[predicted_multiclass_label]) * 100\n",
    "    return combined_result, average_confidence\n",
    "\n",
    "model_paths = ['densenet_multiclass_new_2.h5', 'xception_multiclass_new_1.h5', 'inception_multiclass_new_4.h5', 'vgg_multiclass_new_1.h5', 'resnet_multiclass_new_1.h5']\n",
    "patient_path = '../datasets/test_patient'\n",
    "template_paths = [\n",
    "        '../datasets/ocr_mask/mask_L.jpg', '../datasets/ocr_mask/mask_L_2.jpg', \n",
    "        '../datasets/ocr_mask/mask_L_3.jpg', '../datasets/ocr_mask/mask_L_4.jpg', \n",
    "        '../datasets/ocr_mask/mask_L_white.jpg', '../datasets/ocr_mask/mask_R.jpg', \n",
    "        '../datasets/ocr_mask/mask_R_2.jpg', '../datasets/ocr_mask/mask_R_3.jpg', \n",
    "        '../datasets/ocr_mask/mask_R_4.jpg', '../datasets/ocr_mask/mask_R_5.jpg', \n",
    "        '../datasets/ocr_mask/mask_R_6.jpg', '../datasets/ocr_mask/mask_R_7.jpg', \n",
    "        '../datasets/ocr_mask/mask_R_white.jpg'\n",
    "    ]\n",
    "meta_model_file = 'meta_model.pkl'\n",
    "df_test = './df_test_multiclass_1.csv'\n",
    "\n",
    "final_prediction, average_confidence = body_part_detect(patient_path, model_paths, meta_model_file, template_paths, df_test)\n",
    "print('Final prediction:', final_prediction)\n",
    "print('Average confidence:', average_confidence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e9fa27d-836f-4063-9f29-702c7ffe1cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "\n",
    "# Serialize the function to a file\n",
    "with open('body_part_detect.pkl', 'wb') as f:\n",
    "    dill.dump(body_part_detect, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c02990b-2064-4d75-a404-041aa78dc8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x75c2d9f8a200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 268ms/step\n",
      "1/1 [==============================] - 1s 615ms/step\n",
      "1/1 [==============================] - 0s 436ms/step\n",
      "1/1 [==============================] - 0s 70ms/step\n",
      "1/1 [==============================] - 0s 324ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 15ms/step\n",
      "1/1 [==============================] - 0s 13ms/step\n",
      "1/1 [==============================] - 0s 14ms/step\n",
      "Final prediction: cubiti dextra\n"
     ]
    }
   ],
   "source": [
    "with open('body_part_detect.pkl', 'rb') as f:\n",
    "    loaded_function = dill.load(f)\n",
    "\n",
    "model_paths = ['densenet_multiclass_new_2.h5', 'xception_multiclass_new_1.h5', 'inception_multiclass_new_4.h5', 'vgg_multiclass_new_1.h5', 'resnet_multiclass_new_1.h5']\n",
    "patient_path = '../datasets/test_patient'\n",
    "template_paths = [\n",
    "        '../datasets/ocr_mask/mask_L.jpg', '../datasets/ocr_mask/mask_L_2.jpg', \n",
    "        '../datasets/ocr_mask/mask_L_3.jpg', '../datasets/ocr_mask/mask_L_4.jpg', \n",
    "        '../datasets/ocr_mask/mask_L_white.jpg', '../datasets/ocr_mask/mask_R.jpg', \n",
    "        '../datasets/ocr_mask/mask_R_2.jpg', '../datasets/ocr_mask/mask_R_3.jpg', \n",
    "        '../datasets/ocr_mask/mask_R_4.jpg', '../datasets/ocr_mask/mask_R_5.jpg', \n",
    "        '../datasets/ocr_mask/mask_R_6.jpg', '../datasets/ocr_mask/mask_R_7.jpg', \n",
    "        '../datasets/ocr_mask/mask_R_white.jpg'\n",
    "    ]\n",
    "meta_model_file = 'meta_model.pkl'\n",
    "df_test = './df_test_multiclass_1.csv'\n",
    "\n",
    "final_rediction = loaded_function(patient_path, model_paths, meta_model_file, template_paths, df_test)\n",
    "print('Final prediction:', final_rediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
