{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6adfd8d1-0f25-4e66-a6ca-b20b27533854",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from glob import glob\n",
    "import PIL\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import seaborn as sns\n",
    "import shutil\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.applications.xception import preprocess_input as preprocess_xception\n",
    "from tensorflow.keras.applications.densenet import preprocess_input as preprocess_densenet\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input as preprocess_vgg\n",
    "from tensorflow.keras.applications.inception_v3 import preprocess_input as preprocess_inception\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input as preprocess_resnet\n",
    "from tensorflow.keras.utils import load_img, img_to_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7646ec1d-ff54-4981-8d07-52d06d52faf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 263ms/step\n",
      "1/1 [==============================] - 1s 605ms/step\n",
      "1/1 [==============================] - 0s 420ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 0s 321ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "Final prediction: cubiti dextra\n"
     ]
    }
   ],
   "source": [
    "def body_part_detect(folder_path, model_paths, meta_model_file, template_paths, df_test):\n",
    "    # Load models\n",
    "    densenet_model = load_model(model_paths[0])\n",
    "    xception_model = load_model(model_paths[1])\n",
    "    inception_model = load_model(model_paths[2])\n",
    "    vgg_model = load_model(model_paths[3])\n",
    "    resnet_model = load_model(model_paths[4])\n",
    "\n",
    "    with open(meta_model_file, 'rb') as file:\n",
    "        meta_model = pickle.load(file)\n",
    "    \n",
    "    template_images = [cv2.imread(path) for path in template_paths]\n",
    "\n",
    "    # Helper functions\n",
    "    def preprocess_image(img_path, model_name):\n",
    "\n",
    "        # Load a grayscale image\n",
    "        img = load_img(img_path, color_mode='grayscale', target_size=(224, 224))\n",
    "        \n",
    "        # Convert the image to a numpy array\n",
    "        img_array = img_to_array(img)\n",
    "        \n",
    "        # Replicate the grayscale channel three times to create a pseudo-RGB image\n",
    "        pseudo_rgb_img = np.repeat(img_array, 3, axis=2)\n",
    "    \n",
    "        if model_name == 'xception':\n",
    "            processed_img = preprocess_xception(pseudo_rgb_img)\n",
    "        elif model_name == 'densenet':\n",
    "            processed_img = preprocess_densenet(pseudo_rgb_img)\n",
    "        elif model_name == 'inception':\n",
    "            processed_img = preprocess_inception(pseudo_rgb_img)\n",
    "        elif model_name == 'vgg':\n",
    "            processed_img = preprocess_vgg(pseudo_rgb_img)\n",
    "        elif model_name == 'resnet':\n",
    "            processed_img = preprocess_resnet(pseudo_rgb_img)\n",
    "            \n",
    "        return processed_img\n",
    " \n",
    "    def generate_predictions(model, dataset):\n",
    "        predictions = model.predict(dataset)\n",
    "        return predictions.reshape(predictions.shape[0], -1)\n",
    "\n",
    "    def detect_position(image, template_images):\n",
    "        idx_pos = []\n",
    "        for idx, template in enumerate(template_images):\n",
    "            template_gray = cv2.cvtColor(template, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "            # template matching\n",
    "            match_result = cv2.matchTemplate(image, template_gray, cv2.TM_CCOEFF_NORMED)\n",
    "            \n",
    "            # get max_val to know the detection confidence\n",
    "            min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(match_result)\n",
    "    \n",
    "            # if confident more than 85% return the idx\n",
    "            if max_val >= 0.85:\n",
    "                idx_pos.append(idx)\n",
    "        return idx_pos\n",
    "\n",
    "    patient_predictions = defaultdict(list)\n",
    "    \n",
    "    for filename in os.listdir(folder_path):\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(img_path) and img_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            model_predictions = []\n",
    "            model_names = ['xception', 'densenet', 'inception', 'vgg', 'resnet']\n",
    "            models = [xception_model, densenet_model, inception_model, vgg_model, resnet_model]\n",
    "            \n",
    "            for idx, m in enumerate(model_names):\n",
    "                img = preprocess_image(img_path, m)\n",
    "                img = np.expand_dims(img, axis=0)  # Add a new dimension at the beginning\n",
    "                model_predictions.append(generate_predictions(models[idx], img))\n",
    "            \n",
    "            # Vertically stack the predictions from all models\n",
    "            aggregated_preds = np.hstack(model_predictions)\n",
    "            \n",
    "            predicted_multiclass_label = meta_model.predict(aggregated_preds)\n",
    "            confidence_score = np.max(meta_model.predict_proba(aggregated_preds))\n",
    "    \n",
    "            # Store predictions with confidence\n",
    "            patient_predictions[predicted_multiclass_label[0]].append(confidence_score)\n",
    "\n",
    "    predicted_multiclass_label = max(patient_predictions, key=lambda x: sum(patient_predictions[x]))\n",
    "    \n",
    "    df_test = pd.read_csv(df_test)\n",
    "\n",
    "    # Initialize the LabelEncoder\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit_transform(df_test['body_part'])\n",
    "    predicted_body_part = label_encoder.inverse_transform([predicted_multiclass_label])[0]\n",
    "    \n",
    "    # Final prediction and formatting\n",
    "    combined_result = predicted_body_part\n",
    "    skip_body_part = ['abdomen', 'kepala', 'os_sacro_coccygeus', 'pelvis', 'thorax', 'vertebra_cervical', 'vertebra_lumbosakral', 'vertebra_thoracolumbal']\n",
    "\n",
    "\n",
    "    if predicted_body_part not in skip_body_part:\n",
    "        position_list = []\n",
    "\n",
    "        for filename in os.listdir(folder_path):\n",
    "                # Loop through each image\n",
    "                img_path = os.path.join(folder_path, filename)\n",
    "                if os.path.isfile(img_path) and img_path.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                    image = cv2.imread(img_path)\n",
    "                    # plt.imshow(image)\n",
    "                    # plt.show()\n",
    "                    \n",
    "                    image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY).astype(np.uint8)\n",
    "                    idx_pos = detect_position(image_gray, template_images)\n",
    "                \n",
    "                    # append position\n",
    "                    if any(i in idx_pos for i in range(5)) and any(i in idx_pos for i in range(5, 13)):\n",
    "                        position_list.append('right')\n",
    "                        position_list.append('left')\n",
    "                    elif any(i in idx_pos for i in range(5)):\n",
    "                        position_list.append('left')\n",
    "                    elif any(i in idx_pos for i in range(5, 13)):\n",
    "                        position_list.append('right')\n",
    "                \n",
    "        if len(position_list) > 0:            \n",
    "            if 'right' in position_list and 'left' in position_list:\n",
    "                position = 'bilateral'\n",
    "            elif 'right' in position_list:\n",
    "                position = 'dextra'\n",
    "            elif 'left' in position_list:\n",
    "                position = 'sinistra'\n",
    "            combined_result += ' ' + position\n",
    "    \n",
    "    else:\n",
    "        combined_result += 'None'\n",
    "\n",
    "    return combined_result\n",
    "\n",
    "model_paths = ['densenet_multiclass_new_2.h5', 'xception_multiclass_new_1.h5', 'inception_multiclass_new_4.h5', 'vgg_multiclass_new_1.h5', 'resnet_multiclass_new_1.h5']\n",
    "patient_path = '../datasets/test_patient'\n",
    "template_paths = [\n",
    "        '../datasets/ocr_mask/mask_L.jpg', '../datasets/ocr_mask/mask_L_2.jpg', \n",
    "        '../datasets/ocr_mask/mask_L_3.jpg', '../datasets/ocr_mask/mask_L_4.jpg', \n",
    "        '../datasets/ocr_mask/mask_L_white.jpg', '../datasets/ocr_mask/mask_R.jpg', \n",
    "        '../datasets/ocr_mask/mask_R_2.jpg', '../datasets/ocr_mask/mask_R_3.jpg', \n",
    "        '../datasets/ocr_mask/mask_R_4.jpg', '../datasets/ocr_mask/mask_R_5.jpg', \n",
    "        '../datasets/ocr_mask/mask_R_6.jpg', '../datasets/ocr_mask/mask_R_7.jpg', \n",
    "        '../datasets/ocr_mask/mask_R_white.jpg'\n",
    "    ]\n",
    "meta_model_file = 'meta_model.pkl'\n",
    "df_test = './df_test_multiclass_1.csv'\n",
    "\n",
    "final_rediction = body_part_detect(patient_path, model_paths, meta_model_file, template_paths, df_test)\n",
    "print('Final prediction:', final_rediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e9fa27d-836f-4063-9f29-702c7ffe1cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "\n",
    "# Serialize the function to a file\n",
    "with open('body_part_detect.pkl', 'wb') as f:\n",
    "    dill.dump(body_part_detect, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2c02990b-2064-4d75-a404-041aa78dc8d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 264ms/step\n",
      "1/1 [==============================] - 1s 609ms/step\n",
      "1/1 [==============================] - 0s 421ms/step\n",
      "1/1 [==============================] - 0s 97ms/step\n",
      "1/1 [==============================] - 1s 511ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "Final prediction: cubiti dextra\n"
     ]
    }
   ],
   "source": [
    "with open('body_part_detect.pkl', 'rb') as f:\n",
    "    loaded_function = dill.load(f)\n",
    "\n",
    "model_paths = ['densenet_multiclass_new_2.h5', 'xception_multiclass_new_1.h5', 'inception_multiclass_new_4.h5', 'vgg_multiclass_new_1.h5', 'resnet_multiclass_new_1.h5']\n",
    "patient_path = '../datasets/test_patient'\n",
    "template_paths = [\n",
    "        '../datasets/ocr_mask/mask_L.jpg', '../datasets/ocr_mask/mask_L_2.jpg', \n",
    "        '../datasets/ocr_mask/mask_L_3.jpg', '../datasets/ocr_mask/mask_L_4.jpg', \n",
    "        '../datasets/ocr_mask/mask_L_white.jpg', '../datasets/ocr_mask/mask_R.jpg', \n",
    "        '../datasets/ocr_mask/mask_R_2.jpg', '../datasets/ocr_mask/mask_R_3.jpg', \n",
    "        '../datasets/ocr_mask/mask_R_4.jpg', '../datasets/ocr_mask/mask_R_5.jpg', \n",
    "        '../datasets/ocr_mask/mask_R_6.jpg', '../datasets/ocr_mask/mask_R_7.jpg', \n",
    "        '../datasets/ocr_mask/mask_R_white.jpg'\n",
    "    ]\n",
    "meta_model_file = 'meta_model.pkl'\n",
    "df_test = './df_test_multiclass_1.csv'\n",
    "\n",
    "final_rediction = loaded_function(patient_path, model_paths, meta_model_file, template_paths, df_test)\n",
    "print('Final prediction:', final_rediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
