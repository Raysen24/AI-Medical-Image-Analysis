{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n26\\nTS Yang terhormat\\n\\nPemeriksaan radiografi pelvis proyeksi AP dengan hasil sebagai berikut :\\n\\nKedudukan tulang-tulang pelvis berubah\\nTampak fraktur pada neck femur dextra dengan fragmen fraktur displaced ke cranial\\nCelah sendi coxae dan sakroiliaka kanan-kiri serta simfisis pubis dalam batas normal.\\nJaringan lunak tak tampak lesi patologis.\\n\\n\\nKesan:\\nFraktur pada neck femur dextra\\n\\nTerima kasih atas kerjasamanya,\\n55 pelvis\\nTS Yang terhormat\\n\\nPemeriksaan radiografi pelvis proyeksi AP dengan hasil sebagai berikut :\\n\\nKedudukan tulang-tulang femur dextra berubah\\nTampak fraktur pada intertrochanter femur dextra dengan fragmen fraktur displaced minimal\\nCelah sendi coxae dan sakroiliaka kanan-kiri serta simfisis pubis dalam batas normal.\\nJaringan lunak tak tampak lesi patologis.\\n\\nKesan:\\nFraktur pada intertrochanter femur dextra\\n\\nTerima kasih atas kerjasamanya,\\n56 pelvis\\nTS Yang terhormat\\n\\nPemeriksaan radiografi pelvis proyeksi AP dengan hasil sebagai berikut :\\n\\nKedudukan tulang-tulang pelvis baik.\\nTak tampak fraktur, destruksi, dislokasi, maupun lesi litik/blastik lainnya.\\nCelah sendi coxae dan sakroiliaka kanan-kiri serta simfisis pubis dalam batas normal.\\nJaringan lunak tak tampak lesi patologis.\\n\\n\\nKesan:\\nTak tampak kelainan radiologik.\\n\\n\\nTerima kasih atas kerjasamanya,\\n\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# script to separate report (OK)\n",
    "# script to clean 3 lines of introduction but there are some that only have 2 lines, so need to check for the 3rd line first word -> \"pemeriksaan\" (OK)\n",
    "\n",
    "# script to check whether there is wrong report file in folder\n",
    "# script to detect which \"kesan\" is the conclusion \n",
    "\n",
    "'''\n",
    "26\n",
    "TS Yang terhormat\n",
    "\n",
    "Pemeriksaan radiografi pelvis proyeksi AP dengan hasil sebagai berikut :\n",
    "\n",
    "Kedudukan tulang-tulang pelvis berubah\n",
    "Tampak fraktur pada neck femur dextra dengan fragmen fraktur displaced ke cranial\n",
    "Celah sendi coxae dan sakroiliaka kanan-kiri serta simfisis pubis dalam batas normal.\n",
    "Jaringan lunak tak tampak lesi patologis.\n",
    "\n",
    "\n",
    "Kesan:\n",
    "Fraktur pada neck femur dextra\n",
    "\n",
    "Terima kasih atas kerjasamanya,\n",
    "55 pelvis\n",
    "TS Yang terhormat\n",
    "\n",
    "Pemeriksaan radiografi pelvis proyeksi AP dengan hasil sebagai berikut :\n",
    "\n",
    "Kedudukan tulang-tulang femur dextra berubah\n",
    "Tampak fraktur pada intertrochanter femur dextra dengan fragmen fraktur displaced minimal\n",
    "Celah sendi coxae dan sakroiliaka kanan-kiri serta simfisis pubis dalam batas normal.\n",
    "Jaringan lunak tak tampak lesi patologis.\n",
    "\n",
    "Kesan:\n",
    "Fraktur pada intertrochanter femur dextra\n",
    "\n",
    "Terima kasih atas kerjasamanya,\n",
    "56 pelvis\n",
    "TS Yang terhormat\n",
    "\n",
    "Pemeriksaan radiografi pelvis proyeksi AP dengan hasil sebagai berikut :\n",
    "\n",
    "Kedudukan tulang-tulang pelvis baik.\n",
    "Tak tampak fraktur, destruksi, dislokasi, maupun lesi litik/blastik lainnya.\n",
    "Celah sendi coxae dan sakroiliaka kanan-kiri serta simfisis pubis dalam batas normal.\n",
    "Jaringan lunak tak tampak lesi patologis.\n",
    "\n",
    "\n",
    "Kesan:\n",
    "Tak tampak kelainan radiologik.\n",
    "\n",
    "\n",
    "Terima kasih atas kerjasamanya,\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_file(filepath):\n",
    "    if filepath.endswith('TOTAL.txt'):\n",
    "        pass\n",
    "    else:\n",
    "        return filepath.lower().endswith('.txt')\n",
    "\n",
    "def separate_report(text):\n",
    "    report = {}\n",
    "    current_report = []\n",
    "    num = 1\n",
    "    for sentence in text.split('\\n'):\n",
    "        for word in sentence.split():\n",
    "            # get report number for dict key\n",
    "            if word.isdigit():\n",
    "                num = word\n",
    "            # if word is a digit (means new report) and it is not the first digit (report)\n",
    "            if word.isdigit() and word != text.split()[0]:\n",
    "                # combine all the words into one report and add it to dict\n",
    "                final_report = ' '.join(current_report)\n",
    "                final_report = '\\n'.join([f.lstrip(' ') for f in final_report.splitlines()])\n",
    "                report[num] = final_report\n",
    "                # clear list and append new digit (report)\n",
    "                current_report = []\n",
    "                current_report.append(word)\n",
    "            # elif last word in report, add the final report to the dict\n",
    "            elif word == text.split()[-1]:\n",
    "                current_report.append(word)\n",
    "                final_report = ' '.join(current_report)\n",
    "                final_report = '\\n'.join([f.lstrip(' ') for f in final_report.splitlines()])\n",
    "                report[num] = final_report\n",
    "            else:\n",
    "                current_report.append(word)\n",
    "        current_report.append('\\n')\n",
    "    # {report_num_1: text, report_num_2: text}\n",
    "    return report\n",
    "\n",
    "def makedir(path):\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "    # change permission into read, write, execute\n",
    "    Path(path).chmod(0o777)\n",
    "\n",
    "def generate_separate_report(text, base_dir, filename):\n",
    "    report = separate_report(text)\n",
    "    # ex path: base_dir/body_part/series/filename\n",
    "    # ex filename: body_part-series+reportnum ??\n",
    "    body_part = Path(filename).parent.parent.name\n",
    "    for key, val in report.items():\n",
    "        base_new_filename = f'{body_part}-num{key}_series_1001'\n",
    "        new_filename = f'{base_new_filename}.txt' # need to confirm number and series\n",
    "        new_filepath = os.path.join(base_dir, body_part, base_new_filename, new_filename)\n",
    "        makedir(os.path.join(base_dir, body_part, base_new_filename))\n",
    "        # create each report in the respective folders\n",
    "        with open(new_filepath, 'w') as w:\n",
    "            w.write(val)\n",
    "\n",
    "def remove_start_end(text):\n",
    "    # remove empty lines, start and end sentences that bear no meaning\n",
    "    sentences = [s for s in text.splitlines() if s]\n",
    "    end_word = sentences[-1].split()[0].lower()\n",
    "    start_word = sentences[2].split()[0].lower()\n",
    "    if end_word in ['terima', 'btk']:\n",
    "        start_index = 3 if start_word in ['pemeriksaan', 'foto'] else 2\n",
    "        text = os.linesep.join(sentences[start_index:-1])\n",
    "    else:\n",
    "        start_index = 3 if start_word in ['pemeriksaan', 'foto'] else 2\n",
    "        text = os.linesep.join(sentences[start_index:])\n",
    "    return text\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    punctuations = '''!()[]{};:'\"\\,<>?@#$%^&*~.''' # / is not removed for fraction, - is not removed for range (ex: l3-l4)\n",
    "    new_text = ''\n",
    "    for char in text:\n",
    "        if char not in punctuations: \n",
    "            new_text += char\n",
    "    return new_text\n",
    "\n",
    "def cleaning(text, base_dir, filename):\n",
    "    generate_separate_report(text, base_dir, filename)\n",
    "    text = text.strip()\n",
    "    text = text.lower()\n",
    "    text = remove_start_end(text)\n",
    "    text = remove_punctuations(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_mapping(text: str, file_list: dict):\n",
    "    # will store word mapping to file. format: {word: [filename1, filename2, ...]}\n",
    "    word_mapping = {}\n",
    "    # split compiled text and make it into set\n",
    "    text = set(text.split())\n",
    "    # loop through set\n",
    "    for word in text:\n",
    "        for key, val in file_list.items():\n",
    "            if word == 'vesicolithpreperitoneal':\n",
    "                print(val.split())\n",
    "            # if word in text value of each file dict\n",
    "            if word in val.split() and (word != '-' or '/'):\n",
    "                # add word as key and the filename as value\n",
    "                if word not in word_mapping:\n",
    "                    word_mapping[word] = [key]\n",
    "                else:\n",
    "                    word_mapping[word].append(key)             \n",
    "    return word_mapping\n",
    "\n",
    "def generate_wordlist2(word_mapping: dict, body_part: str, word_list_dir: str):\n",
    "    makedir(word_list_dir)\n",
    "    with open(os.path.join(word_list_dir, f'{body_part}_with_file.txt'), 'w') as w:\n",
    "        # loop through dictionary, generate file with word and filename\n",
    "        for key, val in word_mapping.items():\n",
    "            w.write(key + '     ' + str(val) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body part group: ['abodemen_3_posisi', 'pelvis', 'test'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# directories\n",
    "base_dir = os.path.join('..','datasets','radiology_clean')\n",
    "word_list_dir = os.path.join('..', 'datasets_wordlist_with_file')\n",
    "\n",
    "# body part grouping\n",
    "body_part_group = [f.lower() for f in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, f))]\n",
    "print(\"body part group:\", body_part_group, \"\\n\")\n",
    "\n",
    "# compilation report per body part\n",
    "# format: {body_part: 'all report text for the body part'}\n",
    "body_part_text = {}\n",
    "# compilation of each filename with the text\n",
    "# format: {filename: text, filename2: text}\n",
    "file_text_mapping = {}\n",
    "# store compiled text of each body part\n",
    "compiled_text = ''\n",
    "\n",
    "idx = 0\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for file in files:\n",
    "        # get full filename\n",
    "        filename = os.path.join(root, file)\n",
    "        # get body part\n",
    "        body_part = Path(filename).parent.parent.name\n",
    "        \n",
    "        # if txt file -> report\n",
    "        if txt_file(filename):\n",
    "            f = open(filename, \"r\", encoding=\"unicode_escape\")\n",
    "            text = f.read()\n",
    "            text = cleaning(text, base_dir, filename)\n",
    "\n",
    "            # if still the same body part\n",
    "            if body_part == body_part_group[idx]:\n",
    "                # append to compiled text that contains all txt of the body part\n",
    "                # append to file text mapping\n",
    "                compiled_text += text + ' '\n",
    "                file_text_mapping[file] = text\n",
    "            \n",
    "            # if already different body part\n",
    "            elif body_part != body_part_group[idx]:\n",
    "                # generate wordlist by passing the compiled text\n",
    "                word_mapping = file_mapping(compiled_text, file_text_mapping)\n",
    "                generate_wordlist2(word_mapping, body_part_group[idx], word_list_dir)\n",
    "                compiled_text = text\n",
    "                 # clear compiled text and file text mapping dict, append with new body part, add ix\n",
    "                file_text_mapping = {}\n",
    "                file_text_mapping[file] = text\n",
    "                idx += 1\n",
    "\n",
    "    # if reach end of file\n",
    "    if not dirs:\n",
    "        word_mapping = file_mapping(compiled_text, file_text_mapping)\n",
    "        generate_wordlist2(word_mapping, body_part_group[idx], word_list_dir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
