{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n26\\nTS Yang terhormat\\n\\nPemeriksaan radiografi pelvis proyeksi AP dengan hasil sebagai berikut :\\n\\nKedudukan tulang-tulang pelvis berubah\\nTampak fraktur pada neck femur dextra dengan fragmen fraktur displaced ke cranial\\nCelah sendi coxae dan sakroiliaka kanan-kiri serta simfisis pubis dalam batas normal.\\nJaringan lunak tak tampak lesi patologis.\\n\\n\\nKesan:\\nFraktur pada neck femur dextra\\n\\nTerima kasih atas kerjasamanya,\\n55 pelvis\\nTS Yang terhormat\\n\\nPemeriksaan radiografi pelvis proyeksi AP dengan hasil sebagai berikut :\\n\\nKedudukan tulang-tulang femur dextra berubah\\nTampak fraktur pada intertrochanter femur dextra dengan fragmen fraktur displaced minimal\\nCelah sendi coxae dan sakroiliaka kanan-kiri serta simfisis pubis dalam batas normal.\\nJaringan lunak tak tampak lesi patologis.\\n\\nKesan:\\nFraktur pada intertrochanter femur dextra\\n\\nTerima kasih atas kerjasamanya,\\n56 pelvis\\nTS Yang terhormat\\n\\nPemeriksaan radiografi pelvis proyeksi AP dengan hasil sebagai berikut :\\n\\nKedudukan tulang-tulang pelvis baik.\\nTak tampak fraktur, destruksi, dislokasi, maupun lesi litik/blastik lainnya.\\nCelah sendi coxae dan sakroiliaka kanan-kiri serta simfisis pubis dalam batas normal.\\nJaringan lunak tak tampak lesi patologis.\\n\\n\\nKesan:\\nTak tampak kelainan radiologik.\\n\\n\\nTerima kasih atas kerjasamanya,\\n\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# script to separate report (OK)\n",
    "# script to clean 3 lines of introduction but there are some that only have 2 lines, so need to check for the 3rd line first word -> \"pemeriksaan\" (OK)\n",
    "\n",
    "# script to check whether there is wrong report file in folder\n",
    "# script to detect which \"kesan\" is the conclusion \n",
    "\n",
    "'''\n",
    "26\n",
    "TS Yang terhormat\n",
    "\n",
    "Pemeriksaan radiografi pelvis proyeksi AP dengan hasil sebagai berikut :\n",
    "\n",
    "Kedudukan tulang-tulang pelvis berubah\n",
    "Tampak fraktur pada neck femur dextra dengan fragmen fraktur displaced ke cranial\n",
    "Celah sendi coxae dan sakroiliaka kanan-kiri serta simfisis pubis dalam batas normal.\n",
    "Jaringan lunak tak tampak lesi patologis.\n",
    "\n",
    "\n",
    "Kesan:\n",
    "Fraktur pada neck femur dextra\n",
    "\n",
    "Terima kasih atas kerjasamanya,\n",
    "55 pelvis\n",
    "TS Yang terhormat\n",
    "\n",
    "Pemeriksaan radiografi pelvis proyeksi AP dengan hasil sebagai berikut :\n",
    "\n",
    "Kedudukan tulang-tulang femur dextra berubah\n",
    "Tampak fraktur pada intertrochanter femur dextra dengan fragmen fraktur displaced minimal\n",
    "Celah sendi coxae dan sakroiliaka kanan-kiri serta simfisis pubis dalam batas normal.\n",
    "Jaringan lunak tak tampak lesi patologis.\n",
    "\n",
    "Kesan:\n",
    "Fraktur pada intertrochanter femur dextra\n",
    "\n",
    "Terima kasih atas kerjasamanya,\n",
    "56 pelvis\n",
    "TS Yang terhormat\n",
    "\n",
    "Pemeriksaan radiografi pelvis proyeksi AP dengan hasil sebagai berikut :\n",
    "\n",
    "Kedudukan tulang-tulang pelvis baik.\n",
    "Tak tampak fraktur, destruksi, dislokasi, maupun lesi litik/blastik lainnya.\n",
    "Celah sendi coxae dan sakroiliaka kanan-kiri serta simfisis pubis dalam batas normal.\n",
    "Jaringan lunak tak tampak lesi patologis.\n",
    "\n",
    "\n",
    "Kesan:\n",
    "Tak tampak kelainan radiologik.\n",
    "\n",
    "\n",
    "Terima kasih atas kerjasamanya,\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_file(filepath):\n",
    "    if filepath.endswith('TOTAL.txt'):\n",
    "        pass\n",
    "    else:\n",
    "        return filepath.lower().endswith('.txt')\n",
    "\n",
    "def separate_report(text):\n",
    "    report = {}\n",
    "    current_report = []\n",
    "    num = 1\n",
    "    for sentence in text.split('\\n'):\n",
    "        for word in sentence.split():\n",
    "            # get report number for dict key\n",
    "            if word.isdigit():\n",
    "                num = word\n",
    "            # if word is a digit (means new report) and it is not the first digit (report)\n",
    "            if word.isdigit() and word != text.split()[0]:\n",
    "                # combine all the words into one report and add it to dict\n",
    "                final_report = ' '.join(current_report)\n",
    "                final_report = '\\n'.join([f.lstrip(' ') for f in final_report.splitlines()])\n",
    "                report[num] = final_report\n",
    "                # clear list and append new digit (report)\n",
    "                current_report = []\n",
    "                current_report.append(word)\n",
    "            # elif last word in report, add the final report to the dict\n",
    "            elif word == text.split()[-1]:\n",
    "                current_report.append(word)\n",
    "                final_report = ' '.join(current_report)\n",
    "                final_report = '\\n'.join([f.lstrip(' ') for f in final_report.splitlines()])\n",
    "                report[num] = final_report\n",
    "            else:\n",
    "                current_report.append(word)\n",
    "        current_report.append('\\n')\n",
    "    # {report_num_1: text, report_num_2: text}\n",
    "    return report\n",
    "\n",
    "def makedir(path):\n",
    "    Path(path).mkdir(parents=True, exist_ok=True)\n",
    "    # change permission into read, write, execute\n",
    "    Path(path).chmod(0o777)\n",
    "\n",
    "def generate_separate_report(text, base_dir, filename):\n",
    "    report = separate_report(text)\n",
    "    # ex path: base_dir/body_part/series/filename\n",
    "    # ex filename: body_part-series+reportnum ??\n",
    "    body_part = Path(filename).parent.parent.name\n",
    "    for key, val in report.items():\n",
    "        base_new_filename = f'{body_part}-num{key}_series_1001'\n",
    "        new_filename = f'{base_new_filename}.txt' # need to confirm number and series\n",
    "        new_filepath = os.path.join(base_dir, body_part, base_new_filename, new_filename)\n",
    "        makedir(os.path.join(base_dir, body_part, base_new_filename))\n",
    "        # create each report in the respective folders\n",
    "        with open(new_filepath, 'w') as w:\n",
    "            w.write(val)\n",
    "\n",
    "def remove_start_end(text):\n",
    "    # remove empty lines, start and end sentences that bear no meaning\n",
    "    sentences = [s for s in text.splitlines() if s]\n",
    "    end_word = sentences[-1].split()[0].lower()\n",
    "    start_word = sentences[2].split()[0].lower()\n",
    "    if end_word in ['terima', 'atas', 'btk']:\n",
    "        start_index = 3 if start_word in ['pemeriksaan', 'foto'] else 2\n",
    "        text = os.linesep.join(sentences[start_index:-1])\n",
    "    else:\n",
    "        start_index = 3 if start_word in ['pemeriksaan', 'foto'] else 2\n",
    "        text = os.linesep.join(sentences[start_index:])\n",
    "    return text\n",
    "\n",
    "def remove_punctuations(text):\n",
    "    punctuations = '''!()[]{};:'\"\\,<>?@#$%^&*~.''' # / is not removed for fraction, - is not removed for range (ex: l3-l4)\n",
    "    new_text = ''\n",
    "    for char in text:\n",
    "        if char not in punctuations: \n",
    "            new_text += char\n",
    "    return new_text\n",
    "\n",
    "def remove_unnecessary_symbols(text):\n",
    "\n",
    "    def to_remove(line):\n",
    "        line = re.sub(r'^\\s*-\\s*', '', line)  # Remove dashes at the beginning\n",
    "        line = re.sub(r'(\\s+-\\s+|\\s+-|-\\s+)', ' ', line)  # Remove dashes surrounded by spaces\n",
    "        line = re.sub(r'\\s*-\\s*$', '', line)  # Remove dashes at the end\n",
    "        line = re.sub(r'\\s+/\\s+', ' ', line) # Remove slashes surrounded by spaces only\n",
    "        return line.strip()\n",
    "    \n",
    "    lines = text.split('\\n')\n",
    "\n",
    "    # Remove strip for every line in the list\n",
    "    cleaned_lines = [to_remove(line) for line in lines]\n",
    "\n",
    "    # Join the cleaned lines into a single string\n",
    "    cleaned_text = '\\n'.join(cleaned_lines)\n",
    "\n",
    "    return cleaned_text\n",
    "\n",
    "def cleaning(text, base_dir, filename):\n",
    "    # generate_separate_report(text, base_dir, filename)\n",
    "    text = text.strip()\n",
    "    text = text.lower()\n",
    "    text = remove_punctuations(text)\n",
    "    text = remove_start_end(text)\n",
    "    text = remove_unnecessary_symbols(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate wordlist file\n",
    "def generate_wordlist(compiled_text: dict, word_list_dir):\n",
    "    for key, val in compiled_text.items():\n",
    "        # remove duplicate words by making the text into set\n",
    "        val = set(val.split())\n",
    "        makedir(word_list_dir)\n",
    "        # write the words into one file -> daatasets_wordlist/bodypart.txt\n",
    "        with open(os.path.join(word_list_dir, f'{key}.txt'), 'w') as w:\n",
    "            for word in val:\n",
    "                w.write(word + '\\n')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "body part group: ['abodemen_3_posisi', 'ankle_bilateral', 'ankle_dextra', 'ankle_joint_bilateral', 'ankle_joint_dextra', 'ankle_sinistra', 'antebrachii', 'appendicogram', 'bahu_dextra', 'bahu_kanan_kiri', 'bahu_sinistra', 'bno', 'calvaria', 'clavicual_kanan', 'cruris', 'cubiti', 'femur_bilateral', 'femur_dextra', 'femur_sinistra', 'genu', 'hip_joint', 'humerus', 'humerus_biateral', 'humerus_dextra', 'humerus_sinistra', 'manus', 'mastoid_bilateral', 'os_sacro_coccygeus', 'pedis_dextra', 'pedis_sinistra', 'pelvis', 'schedel4', 'sinus_paranasal', 'thorax', 'vertebra_cervical', 'vertebra_lumbosakral', 'vertebra_thoracolumbal', 'wrist_joint_bilateral', 'wrist_joint_dextra', 'wrist_joint_sinistra'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# directories\n",
    "base_dir = os.path.join('..','datasets','radiology_clean')\n",
    "word_list_dir = os.path.join('..', 'datasets_wordlist')\n",
    "missing_kesan_file = os.path.join('..','report_analysis','all_files_missing_kesan.txt')\n",
    "\n",
    "with open(missing_kesan_file, 'r', encoding='utf-8') as file:\n",
    "    missing_kesan_file_list = [line.strip() for line in file]\n",
    "\n",
    "# body part grouping\n",
    "body_part_group = [f.lower() for f in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, f))]\n",
    "print(\"body part group:\", body_part_group, \"\\n\")\n",
    "\n",
    "aggregated_report_list = ['BNO-231027-report-1.txt', 'clavicual_kanan-Series_1001_0000-gabung-report-1.txt', 'pelvis-2310022-gabung-report-1.txt', 'pelvis-2310024-report-1.txt', 'pelvis-2310025-report-1.txt', 'pelvis-2310300066-report-1.txt', 'Thorax-231020_Brobkhopneumonia-report-1.txt', 'Thorax-231020_Cardiomegaly-report-1.txt', 'Thorax-231020_Pneumonia-Pneumonia-report-1.txt', 'Thorax-231021_231022-Cardiomegaly-report-1.txt', 'Thorax-231021_231022-diagnosa_gabung-report-3.txt', 'Thorax-231021_231022-Pneumonia-report-2.txt', 'Thorax-231021_231022_Cardiomegaly-Cardiomegaly-report-1.txt', 'Thorax-231021_231022_Pneumonia-Pneumonia-report-1.txt', 'Thorax-231023-Bronkhopneumonia-report-1.txt', 'Thorax-231023-gabung-report-3.txt', 'Thorax-231023-Pneumonia-report-2.txt', 'Thorax-231024-pneumonia-report-2.txt', 'Thorax-231024-report-3.txt', 'Thorax-231025-gabung-report-1.txt', 'Thorax-231025-pneumonia-report-3.txt', 'Thorax-231025-pneumonia_cardiomegaly-report-2.txt', 'Thorax-231026-gabung-report-2.txt', 'Thorax-231026-pneumonia-report-3.txt', 'Thorax-231027-pneumonia-report-3.txt', 'Thorax-231028-pneumonia-report-3.txt', 'Thorax-231028-report-4.txt', 'Thorax-231029-gabung-report-1.txt', 'Thorax-231030-report-1.txt', 'Thorax-231101-report-1.txt', 'Thorax-231103-report-1.txt', 'Thorax-231105-report-1.txt', 'Thorax-231106-report-1.txt', 'Thorax-231107-report-1.txt', 'Thorax-231108-report-1.txt', 'Thorax-231109-report-1.txt', 'Thorax-231110-report-1.txt', 'Thorax-231111-report-1.txt', 'Thorax-231112-report-1.txt', 'Thorax-231113-report-1.txt', 'Thorax-231114-report-1.txt', 'Thorax-231115-report-1.txt', 'Thorax-231116-report-1.txt', 'Thorax-231118-report-1.txt', 'Thorax-231119-report-1.txt', 'Thorax-231120-report-1.txt', 'Thorax-231121-report-1.txt', 'Thorax-231122-report-1.txt', 'Thorax-231123-report-1.txt', 'Thorax-231124-report-1.txt', 'Thorax-231125-report-1.txt', 'Thorax-231126-report-1.txt', 'Thorax-231127-report-1.txt', 'Thorax-231128-report-1.txt', 'Thorax-231129-report-1.txt', 'Thorax-231130-report-1.txt', 'Thorax-231201-report-1.txt', 'Thorax-231202-report-1.txt', 'Thorax-231203-report-1.txt', 'Thorax-231204-report-1.txt', 'Thorax-231205-report-1.txt', 'Thorax-231206-report-1.txt', 'Thorax-231207-report-1.txt', 'Thorax-231208-report-1.txt', 'Thorax-231209-report-1.txt', 'Thorax-231210-report-1.txt', 'Thorax-231211-report-1.txt', 'Thorax-231212-report-1.txt', 'Thorax-231213-report-1.txt', 'Thorax-231214-report-1.txt', 'Thorax-231215-report-1.txt', 'Thorax-231216-report-1.txt', 'Thorax-231217-report-1.txt', 'Thorax-231218-report-1.txt', 'Thorax-231222-report-1.txt', 'Thorax-240101-cardiomegaly-report-2.txt', 'Thorax-240101-report-4.txt', 'Thorax-240102-report-1.txt', 'Thorax-240103-report-1.txt', 'Thorax-240104-report-1.txt', 'Thorax-240105-report-1.txt', 'Thorax-240106-report-1.txt', 'Thorax-240107-report-1.txt', 'Thorax-240108-report-1.txt', 'Thorax-240109-report-1.txt', 'Thorax-240110-report-1.txt', 'Thorax-240111-report-1.txt', 'Thorax-240112-report-1.txt', 'Thorax-240113-report-1.txt', 'Thorax-240114-report-1.txt', 'Thorax-240115-report-1.txt', 'Thorax-240117-report-1.txt', 'Thorax-240119-report-1.txt', 'Thorax-240120-report-1.txt', 'Thorax-240121-report-1.txt', 'Thorax-240122-report-1.txt', 'Thorax-240124-report-1.txt', 'Thorax-240126-report-1.txt', 'Thorax-240127-report-1.txt', 'Thorax-240128-report-1.txt']\n",
    "\n",
    "# compilation report per body part\n",
    "# format: {body_part: 'all report text for the body part'}\n",
    "body_part_text = {}\n",
    "\n",
    "for root, dirs, files in os.walk(base_dir):\n",
    "    for file in files:\n",
    "        # get full filename\n",
    "        filename = os.path.join(root, file)\n",
    "        # get body part\n",
    "        body_part = Path(filename).parent.parent.name\n",
    "        if body_part in body_part_group:\n",
    "            # if txt file -> report\n",
    "            if txt_file(filename):\n",
    "                if file in missing_kesan_file_list: break\n",
    "                if file in aggregated_report_list: break\n",
    "                f = open(filename, \"r\", encoding=\"unicode_escape\")\n",
    "                text = f.read()\n",
    "                text = cleaning(text, base_dir, filename)\n",
    "\n",
    "                # append text to dict\n",
    "                if body_part not in body_part_text:\n",
    "                    body_part_text[body_part] = text + ' '\n",
    "                else:\n",
    "                    body_part_text[body_part] += text + ' '\n",
    "                \n",
    "generate_wordlist(body_part_text, word_list_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
