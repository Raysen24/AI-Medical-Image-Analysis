{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, torch, transformers\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from io import BytesIO\n",
    "from torchvision.utils import make_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kimbe\\Documents\\GitHub\\radiology\\autocaption\\medicap\\mcap-venv\\lib\\site-packages\\huggingface_hub\\file_download.py:797: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kimbe\\Documents\\GitHub\\radiology\\autocaption\\medicap\\mcap-venv\\lib\\site-packages\\transformers\\models\\convnext\\feature_extraction_convnext.py:28: FutureWarning: The class ConvNextFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ConvNextImageProcessor instead.\n",
      "  warnings.warn(\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'GPT2Tokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "ckpt_name = 'aehrc/medicap'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "encoder_decoder = transformers.AutoModel.from_pretrained(ckpt_name, trust_remote_code=True).to(device)\n",
    "encoder_decoder.eval()\n",
    "image_processor = transformers.AutoFeatureExtractor.from_pretrained(ckpt_name)\n",
    "\n",
    "test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=image_processor.size['shortest_edge']),\n",
    "        transforms.CenterCrop(size=[\n",
    "            image_processor.size['shortest_edge'],\n",
    "            image_processor.size['shortest_edge'],\n",
    "        ]\n",
    "        ),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(\n",
    "            mean=image_processor.image_mean,\n",
    "            std=image_processor.image_std,\n",
    "        ),\n",
    "    ]\n",
    ")\n",
    "\n",
    "tokenizer = transformers.PreTrainedTokenizerFast.from_pretrained(ckpt_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 384, 384])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = [\n",
    "    '../Thorax-231030-2310300175_Series_1001_0000-64.jpg'\n",
    "]\n",
    "\n",
    "for i, _ in enumerate(images):\n",
    "    images[i] = Image.open(images[i])\n",
    "    images[i] = images[i].convert('RGB')\n",
    "    images[i] = test_transforms(images[i])\n",
    "\n",
    "images = torch.stack(images, dim=0)\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[50257, 45170,  1395,    12,  2433,  4478,   257,  1364,  3339,  1523,\n",
       "           914,  4241,    13, 50256]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = encoder_decoder.generate(\n",
    "    pixel_values=images.to(device),\n",
    "    bos_token_id=tokenizer.bos_token_id,\n",
    "    eos_token_id=tokenizer.eos_token_id,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    "    return_dict_in_generate=True,\n",
    "    use_cache=True,\n",
    "    max_length=256,\n",
    "    num_beams=4,\n",
    ")\n",
    "outputs.sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chest X-ray showing a left pleural effusion.']\n"
     ]
    }
   ],
   "source": [
    "captions = [tokenizer.decode(seq, skip_special_tokens=True) for seq in outputs.sequences]\n",
    "print(captions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcap-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
